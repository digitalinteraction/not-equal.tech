---
title: MiniCoDe
description: "Minimize algorithmic bias in Collaborative Decision Making with
  Design Fiction "
image: /uploads/minicode_01.svg
themes:
  - algorithmic-social-justice
project_types:
  - Funded Project
project_tags:
  - algorithms
  - design fiction
project_lead:
  - name: Alessio Malizia, University of Hertfordshire
    email: "a.malizia@herts.ac.uk "
investigators:
  - name: Silvio Carta, University of Hertfordshire
partners: []
page_sections:
  - type: video-block
    youtube_video_id: ou5TY-Qv948
  - type: text-block
    text: The Design Fiction Toolkit helps developers to apply social justice
      principles during the Machine Learning development pipeline and to signal
      to researchers where further work is needed. It responds to the needs of
      product managers, developers, and data scientists of ML applications to
      mitigate bias. The intention is to develop the Toolkit further and adapt
      it to two use cases that emerged during the research â€“ in educational
      settings as part of an ethics awareness activity and in small digital
      teams within innovative start-ups interested in ethical design features.
  - type: video-block
    video_embed_code: "https://vimeo.com/653774257  "
  - type: link-block
    title: Publications
    buttons:
      - text: View the Paper
        url: https://www.hhai-conference.org/wp-content/uploads/2022/06/hhai-2022_paper_58.pdf
        content: "MiniCoDe Workshops. Minimise Algorithmic Bias in Collaborative
          Decision Making with Design Fiction: "
      - text: "Co-Creation and Co-Design Methodologies to address Social Justice and
          Ethics in Machine Learning:"
        url: https://drive.google.com/file/d/1dfxfrsQH42qpIwUbG622b7cbyHvdPH58/view?usp=sharing
      - text: Read the Proposal
        url: https://drive.google.com/drive/folders/1efppw8ZUni6GJRQOBpu8b4MLg01QSn2p?usp=sharing
      - text: View the Report
        url: "https://drive.google.com/drive/folders/1TfmX6NJ-lYqgmlYV2pB7hDBrXgEp3nWM?\
          usp=sharing "
---
This project aimed to tackle social injustice in future algorithmic-based decision-making applications by devising strategies to expose, counterbalance, and remedy bias and exclusion built into algorithms, considering fairness, transparency, and accountability. The project employed a design fiction approach to developing a toolkit in a collaborative workshop session with supporting materials to be used by stakeholders to experiment with scenarios to expose potential bias and reflect on mitigation strategies early in the design process.